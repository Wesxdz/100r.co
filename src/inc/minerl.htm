<h3><a href="https://minerl.io/basalt/">MineRL BASALT Competition 2022</a></h3>
<br/>
<br/>
<div class="image-container">
    <img src="../media/content/minerl/tile_sand.png" class="pixel-image" alt="Sand tile">
    <img src="../media/content/minerl/tile_grass_top.png" class="pixel-image" alt="Grass tile">
    <img src="../media/content/minerl/tile_dirt_side.png" class="pixel-image" alt="Dirt tile">
    <img src="../media/content/minerl/tile_cobblestone.png" class="pixel-image" alt="Cobblestone tile">
</div>
<p><i>Pixel art tile textures generated by a Dreambooth model I trained.</i></p>

<p>My strategy was inspired by <a href="https://www.youtube.com/watch?v=D9xVj7oLVh4">this keynote by Josh Tenenbaum</a>.</p>
<p>My top priority for the contest was to create a prior for intuitive physics of voxel terrain, ignoring dynamic geometry. My theory was that if the input to VPT fine tuning was a symbolic world model instead of raw pixels, then training any objective would be much easier (possible).</p>
<ul>
    <p>This invovled:</p>
    <li>Creating an neural network to predict a voxel heightmap relative to a camera view</li>
    <li>The agent running a headless game engine simulation of its actions in the context of a scene predition</li>
</ul>

<p>I was only able to pass through two milestones within the time limits of the competition. I used Blender to <a href="https://docs.blender.org/manual/en/latest/advanced/command_line/render.html">headlessly render</a> tens of thousands of synthetically generated voxel heightmaps and their corresponding occlusion renders (each voxel index was represented by a distinct color).</p>
<p>Then, I trained a neural network on this purely synthetic data: voxel_sight <a href="https://github.com/Wesxdz/voxel_sight">github repo</a></p>
<p>I originally tried to visualize the outputs by recreating the 3D scenes, but I found it was easier to view predicted heightmaps as 2D images!</p>
<video controls autoplay muted>
    <source src="../media/content/minerl/occlusion_prediction.mp4" type="video/mp4">
</video>
<p>From left to right (1. actual scene data), (2. predicted voxel existence), (3. predicted voxel heights), (4. predicted composite)</p>
<p>One thing I wish I had time for is to train on a larger dataset of textures and scenes, as well as performing more data augmentation that would allow better generalization to the non-voxel entities of Minecraft.</p>
<p>I was sponsored to virtually attend NeurIPS, which was super exciting!</p>
<p>My experiments here helped me make progress on procedural infinite world generation with diffusion models, and start to design a seed curation interface for texture generation.</p>
<video controls autoplay muted>
    <source src="../media/content/minerl/procedural_inpaint.mp4" type="video/mp4">
</video>